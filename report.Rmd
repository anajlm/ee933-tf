---
title: 'Estudo de Caso 3 - Comparação de desempenho de duas configurações de um algoritmo de otimização'
author: "Ana Júlia de Lima Martins, Antônio Carlos da Anunciação, Melchior Augusto Syrio de Melo"
date: "24 de dezembro de 2024"
output:
  pdf_document:
    fig_caption: yes
  html_document:
    df_print: paged
---

```{r setup,results='hide',warning=FALSE,echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away.
suppressPackageStartupMessages({
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
# if (!require(devtools, quietly = TRUE)){
#       install.packages("devtools")
#       }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
# if (!require(GGally, quietly = TRUE)){
#       install.packages("GGally")
#       }
if (!require(dplyr, quietly = TRUE)){
      install.packages("dplyr")
}
if (!require(reshape2, quietly = TRUE)){
      install.packages("reshape2")
}
if (!require(multcomp, quietly = TRUE)){
      install.packages("multcomp")
}})
```

## 1.2. Tamanho amostral

Nesta seção, discutimos a definição do número de instâncias e de repetições necessárias para o experimento, a fim de obter um poder do teste de pelo menos $\pi^* = 0,8$, para detectar diferenças iguais ou superiores a um tamanho de efeito minimamente relevante $d^* = 0,5$, com nível de significância $\alpha = 0,05$.

### 1.2.1. Estimando o número de instâncias (blocos)

Sob a hipótese alternativa H1, a estatística $t_0$ segue uma distribuição t não central (Mathews, 2010) com parâmetro de não centralidade dado por:

$$ncp = \frac{(\mu_D - \mu_0) \sqrt{N}}{\hat{\sigma}_{\Phi}} = \frac{\delta \sqrt{N}}{\hat{\sigma}_\Phi} = d \sqrt{N}.$$
em que $N$ é o número de instâncias necessárias.

Assumindo uma medida de relevância mínima  $d^* = |\delta^*| / \sigma_{\Phi}$, o poder do teste $\pi^*$ é dado pela integral da distribuição t não central com $ncp^* = d^* \sqrt{N}$ sobre os valores de $t_0$ para os quais a hipótese nula $H_0$ é rejeitada (Campelo et. al., 2019):

$$\pi^* = 1 - \beta^* = 1 - \int_{t = t^{(N-1)}_{\alpha/2}}^{t^{(N-1)}_{1-\alpha/2}} \left[ t^{(N-1)}_{\,|\, \text{ncp}^*|} \right] dt$$

Finalmente, o número de instâncias pode ser calculado como o menor inteiro $N$ tal que o poder do teste $\pi^*$ seja igual ou maior que o poder desejado. No caso da hipótese alternativa unilateral, temos que:

$$N^* = \min N \, \bigg| \, t^{(N-1)}_{1-\alpha} \leq t^{(N-1)}_{\beta^* \, ; \, |\text{ncp}^*|}$$


```{r blocos,message=FALSE}
d = 0.5        # Mínima diferença de importância prática (padronizada)
alpha <- 0.05  # Nível de significância
p <- 1 - alpha # Nível de confiança

n <- 2
power <- 0
while (power < 0.8)
{
  df <- n - 1         # n - 1 graus de liberdade
  ncp <- d * sqrt(n)  # Non-centrality parameter

  power <- pt(qt(p,df), df, ncp=ncp, lower.tail=FALSE)
  n <- n + 1
}
n
power
```


### 1.2.2. Estimando o número de repetições por bloco

A abordagem proposta para calcular o número de repetições para o RCBD é similar ao procedimento para um CRD (_Completely Randomized Design_).

Para o CRD, o parâmetro de não-centralidade é definido como:

$$\delta^2 = \frac{n \sum_{i=1}^a (\mu_i - \mu)^2}{\sigma^2}$$
A variabilidade intra-grupo, necessária para calcular o _ncp_, corresponde a variância residual estimada, i.e., a variabilidade não explicada pelo fator experimental e pelo fator bloqueado. Neste experimento, essa variabilidade foi estimada a partir de um estudo piloto com 30 repetições por bloco.

Uma vez definido o _ncp_, a estatística F segue a seguinte distribuição:

$$F \sim\begin{cases}  F_{a-1, a(n-1)} & \text{sob } H_0 \\ F_{a-1, a(n-1), \delta^2} & \text{sob } H_1 \end{cases}$$

O valor crítico $F^*$ para rejeitar $H_0$ com nível de significância $\alpha = 0,05$ é dado por:

$$F^* = F_{a-1, a(n-1), \alpha}$$

Esse valor pode ser calculado usando o seguinte comando em R:

```r
F.crit <- qf(alpha, a-1, a*(n-1), lower.tail = FALSE) # syntax
```

Por definição, o poder do teste é a probabilidade de rejeitar a hipótese nula ($H_0$) quando a hipótese alternativa $H_1$ é verdadeira:

$$\text{Poder} = P(\text{Rejeitar } H_0 | H_1 \text{ é verdadeira}).$$

Isso é equivalente a:

$$P(F(a-1, a(n-1), \delta^2) \geq F^*)$$
Sendo assim, o poder do teste pode ser calculado usando o seguinte comando:

```r
power <- pf(F.crit, a-1, a*(n-1), ncp = ncp, lower.tail = FALSE) # syntax
```

A estratégia consiste em variar o número de repetições $n$, considerando $a = 2$ níveis do fator de interesse, até obter um poder do teste igual ou superior ao poder desejado ($\pi \geq 0,8$)


```{r carregamentoDadosPiloto,message=FALSE}
# Carregar bibliotecas necessárias
library(dplyr)
library(readr)
library(stringr)

# Definir o diretório onde os arquivos estão localizados
diretorio <- "resultados/Piloto2/"  # Substitua pelo caminho correto

# Listar todos os arquivos CSV no diretório
arquivos <- list.files(path = diretorio, pattern = "*teste.csv", full.names = TRUE)

# Função para extrair o nome do algoritmo do nome do arquivo
extrair_algoritmo <- function(nome_arquivo) {
  # Remove o caminho e mantém apenas o nome do arquivo
  nome_limpo <- basename(nome_arquivo)
  # Extrai o algoritmo baseado no padrão do nome do arquivo
  algoritmo <- str_extract(nome_limpo, "MLP|RF|SVM|XGB")
  return(algoritmo)
}

# Ler e combinar os arquivos em um único dataframe, adicionando a coluna "Algoritmo"
dados <- lapply(arquivos, function(arquivo) {
  df <- read.csv(arquivo)
  df$Algoritmo <- extrair_algoritmo(arquivo)  # Adiciona a coluna Algoritmo
  df <- df[, c("Algoritmo", setdiff(names(df), "Algoritmo"))]  # Reorganiza as colunas
  return(df)
}) %>%
  bind_rows()

# Verificar os dados carregados
str(dados)
head(dados)

```


```{r dataplot,fig.width=8,echo=TRUE,message=FALSE,label="dataplot",fig.cap="Desempenho médio dos algoritmos por nível de ruído"}
# Carregar bibliotecas
library(ggplot2)
library(dplyr)

# Transformar Percentual de Ruído em fator (se ainda não estiver)
dados$percentualRuidoTreinamento <- as.factor(dados$percentualRuidoTreinamento)

# Agregar os dados: média da acurácia por algoritmo e nível de ruído
aggdata <- aggregate(x = dados$acuracia, 
                     by = list(Algoritmo = dados$Algoritmo, 
                               percentualRuidoTreinamento = dados$percentualRuidoTreinamento), 
                     FUN = mean)

# Rename columns
names(aggdata) <- c("Algoritmo", 
                    "Percentual_Ruido_Treinamento",
                    "Acuracia_Media")

# Coerce categorical variables to factors
for (i in 1:2){
      aggdata[, i] <- as.factor(aggdata[, i])
}

#pdf("./figs/ggplot_piloto.pdf", width = 5, height = 5) # <-- uncomment to save plot

# Gráfico de linhas para visualizar o impacto do ruído na acurácia
p <- ggplot(aggdata, aes(x = Percentual_Ruido_Treinamento, 
                         y = Acuracia_Media, 
                         group = Algoritmo, 
                         colour = Algoritmo))
p <- p + geom_line(linetype=2) + geom_point(size=5)
p + labs(title = "Desempenho dos Algoritmos por Nível de Ruído",
          x = "Percentual de Ruído no Treinamento",
          y = "Acurácia Média")

#dev.off() # <-- uncomment this if you uncommented the pdf() command above

```



```{r repeticoes2,message=FALSE}
alpha <- 0.05 # nível de significância
d <- 0.5
a <- length(unique(aggdata$Algoritmo))  # Número de algoritmos
n_max <- 100 # Número máximo de epetições por instância

# Dataframe para armazenar os resultados
# Criar dataframe para armazenar os resultados
repeticoes <- data.frame(
  Algoritmo = character(),
  Repeticoes = integer(),
  Poder = numeric()
)

for (ruido in unique(aggdata$PercentualRuidoTreinamento)) {
  # Calcula n para cada instância para atingir poder >= 0.8
  n <- 2
  power <- 0
  
  # Obter desvio padrão da acurácia média nos algoritmos para esse nível de ruído
  sd <- sd(aggdata$Acuracia_Media[aggdata$PercentualRuidoTreinamento == ruido])

  while (power < 0.8)
  {
    df1 <- a - 1 # Graus de liberdade do numerador
    df2 <- a * (n - 1) # Graus de liberdade do denominador
    
    # Calcular a média da acurácia para cada algoritmo
    mu_algoritmo <- tapply(aggdata$Acuracia_Media[aggdata$PercentualRuidoTreinamento == ruido],
                            aggdata$Algoritmo, mean)
     
    # Média global da acurácia nesse nível de ruído
    mu_global <- mean(mu_algoritmo)

    # Calcula o NCP
    ncp <- (n * sum((mu_algoritmo - mu_global)^2)) / (sd^2)

    F.crit <- qf(alpha, df1, df2, lower.tail = FALSE)

    power <- pf(F.crit, df1, df2, ncp, lower.tail = FALSE)
    
    if (n >= n_max) {
      break
    } else {
      n = n + 1
    }
    
    # Armazenar resultados
    repeticoes <- rbind(repeticoes, 
                      data.frame(PercentualRuidoTreinamento = ruido, 
                                 Repeticoes = n, 
                                 Poder = power))
  }
  
  # Salvar resultados em um arquivo CSV
  write.csv(repeticoes, "repeticoes.csv", row.names = FALSE)

}
```


## 3. Análise Exploratória

Antes de realizar os testes de hipótese, foi realizada uma análise exploratória para obter uma visão geral dos dados. A Figura @ref(fig:dataplot) fornece um gráfico para comparar o desempenho médio das duas configuração por dimensão.

```{r carregamentoDadosExperimento,message=FALSE}
# Carregar bibliotecas necessárias
library(dplyr)
library(readr)
library(stringr)

# Definir o diretório onde os arquivos estão localizados
diretorio <- "resultados/Experimento/"  # Substitua pelo caminho correto

# Listar todos os arquivos CSV no diretório
arquivos <- list.files(path = diretorio, pattern = "*teste.csv", full.names = TRUE)

# Função para extrair o nome do algoritmo do nome do arquivo
extrair_algoritmo <- function(nome_arquivo) {
  # Remove o caminho e mantém apenas o nome do arquivo
  nome_limpo <- basename(nome_arquivo)
  # Extrai o algoritmo baseado no padrão do nome do arquivo
  algoritmo <- str_extract(nome_limpo, "MLP|RF|SVM|XGB")
  return(algoritmo)
}

# Ler e combinar os arquivos em um único dataframe, adicionando a coluna "Algoritmo"
dados <- lapply(arquivos, function(arquivo) {
  df <- read.csv(arquivo)
  df$Algoritmo <- extrair_algoritmo(arquivo)  # Adiciona a coluna Algoritmo
  df <- df[, c("Algoritmo", setdiff(names(df), "Algoritmo"))]  # Reorganiza as colunas
  return(df)
}) %>%
  bind_rows()

# Verificar os dados carregados
str(dados)
head(dados)

```

```{r dataplot,fig.width=8,echo=TRUE,message=FALSE,label="dataplot",fig.cap="Desempenho médio dos algoritmos por nível de ruído"}
# Carregar bibliotecas
library(ggplot2)
library(dplyr)

# Transformar Percentual de Ruído em fator (se ainda não estiver)
dados$percentualRuidoTreinamento <- as.factor(dados$percentualRuidoTreinamento)

# Agregar os dados: média da acurácia por algoritmo e nível de ruído
aggdata <- aggregate(x = dados$acuracia, 
                     by = list(Algoritmo = dados$Algoritmo, 
                               percentualRuidoTreinamento = dados$percentualRuidoTreinamento), 
                     FUN = mean)

# Rename columns
names(aggdata) <- c("Algoritmo", 
                    "Percentual_Ruido_Treinamento",
                    "Acuracia_Media")

# Coerce categorical variables to factors
for (i in 1:2){
      aggdata[, i] <- as.factor(aggdata[, i])
}

#pdf("./figs/ggplot_experimento.pdf", width = 5, height = 5) # <-- uncomment to save plot

# Gráfico de linhas para visualizar o impacto do ruído na acurácia
p <- ggplot(aggdata, aes(x = Percentual_Ruido_Treinamento, 
                         y = Acuracia_Media, 
                         group = Algoritmo, 
                         colour = Algoritmo))
p <- p + geom_line(linetype=2) + geom_point(size=5)
p + labs(title = "Desempenho dos Algoritmos por Nível de Ruído",
          x = "Percentual de Ruído no Treinamento",
          y = "Acurácia Média")

#dev.off() # <-- uncomment this if you uncommented the pdf() command above

```


## 4. Análise Estatística

Para validar nossas observações iniciais, realizamos um teste ANOVA para avaliar as diferenças no desempenho dos algoritmos.

```{r fitmodel,results='hold'}
model <- aov(Acuracia_Media ~ Algoritmo + Percentual_Ruido_Treinamento, data = aggdata)
summary(model)
```

A Figura @ref(modelplot) mostra o modelo resultante do teste estatístico.

```{r modelplot,results='hold',label="modelplot"}
par(mfrow = c(2, 2))
plot(model, pch = 20, las = 1)
```


### 5. Verificação das Premissas do Modelo

#### 5.1 Normalidade

```{r shapiro,fig.width=8,echo=TRUE,message=FALSE, fig.cap = "Teste de Shapiro-Wilk"}
# Check normality
shapiro.test(model$residuals)

library(car)
# png(filename = "../figs/qqplot.png",
#     width = 600, height = 600,
#     bg = "transparent")

qqPlot(retornos_melt,
       pch = 16,
       lwd = 3,
       cex = 2,
       las = 1)
# dev.off()

```

#### 5.2 Homoscedasticidade

Igualdade das variâncias

```{r homoscedasticity,fig.width=8,echo=TRUE,message=FALSE, fig.cap = "Teste de Shapiro-Wilk"}
fligner.test(Acuracia_Media ~ interaction(Algoritmo, Percentual_Ruido_Treinamento), 
             data = aggdata)
```

```
# png(filename = "../figs/papervar.png",
#     width = 600, height = 600,
#     bg = "transparent")
plot(x    = my.model$fitted.values,
     y    = my.model$residuals,
     cex  = 2,
     las  = 1,
     pch  = 16,
     xlab = "Fitted values",
     ylab = "Residuals")
grid(nx = NULL, ny = NULL,
     lwd = 2, col = "#44444422")
# dev.off()
```



### 8. Referências

[1] Mathews, P.: Sample Size Calculations: Practical Methods for Engineers and Scientists, 1st edn. Matthews Malnar & Bailey Inc., Fairport Harbor (2010)

[2] Campelo, F., Takahashi, F. Sample size estimation for power and accuracy in the experimental comparison of algorithms. J Heuristics 25, 305–338 (2019). https://doi.org/10.1007/s10732-018-9396-7